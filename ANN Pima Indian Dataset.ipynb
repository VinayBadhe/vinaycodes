{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e22d4d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.13.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.13.0\n",
      "  Using cached tensorflow_intel-2.13.0-cp39-cp39-win_amd64.whl (276.5 MB)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (21.3)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.56.0-cp39-cp39-win_amd64.whl (4.2 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3.4)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.3)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.13.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.11)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: opt-einsum, grpcio, google-pasta, gast, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 gast-0.4.0 google-auth-2.22.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.56.0 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-intel-2.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac91025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc3485b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49df2431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      6  148  72  35    0  33.6  0.627  50  1\n",
       "0     1   85  66  29    0  26.6  0.351  31  0\n",
       "1     8  183  64   0    0  23.3  0.672  32  1\n",
       "2     1   89  66  23   94  28.1  0.167  21  0\n",
       "3     0  137  40  35  168  43.1  2.288  33  1\n",
       "4     5  116  74   0    0  25.6  0.201  30  0\n",
       "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "762  10  101  76  48  180  32.9  0.171  63  0\n",
       "763   2  122  70  27    0  36.8  0.340  27  0\n",
       "764   5  121  72  23  112  26.2  0.245  30  0\n",
       "765   1  126  60   0    0  30.1  0.349  47  1\n",
       "766   1   93  70  31    0  30.4  0.315  23  0\n",
       "\n",
       "[767 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_data=pd.read_csv('pima-indians-diabetes.csv')\n",
    "pima_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90b47eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pima_data.iloc[:,0:8]\n",
    "Y = pima_data.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dedf3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd95a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c2faf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14cd175c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "52/52 [==============================] - 1s 9ms/step - loss: 10.4724 - accuracy: 0.6394 - val_loss: 4.4755 - val_accuracy: 0.6732\n",
      "Epoch 2/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.7432 - accuracy: 0.6433 - val_loss: 1.5797 - val_accuracy: 0.5906\n",
      "Epoch 3/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.2578 - accuracy: 0.6491 - val_loss: 0.9550 - val_accuracy: 0.6063\n",
      "Epoch 4/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7866 - accuracy: 0.6433 - val_loss: 0.8455 - val_accuracy: 0.5315\n",
      "Epoch 5/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.6530 - val_loss: 0.8017 - val_accuracy: 0.5866\n",
      "Epoch 6/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.6413 - val_loss: 0.7903 - val_accuracy: 0.5906\n",
      "Epoch 7/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.6511 - val_loss: 0.7729 - val_accuracy: 0.6063\n",
      "Epoch 8/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6589 - val_loss: 0.7684 - val_accuracy: 0.6181\n",
      "Epoch 9/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6589 - val_loss: 0.7657 - val_accuracy: 0.6063\n",
      "Epoch 10/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.6706 - val_loss: 0.7537 - val_accuracy: 0.6181\n",
      "Epoch 11/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.6706 - val_loss: 0.7643 - val_accuracy: 0.5669\n",
      "Epoch 12/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.6823 - val_loss: 0.7645 - val_accuracy: 0.5709\n",
      "Epoch 13/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6881 - val_loss: 0.7284 - val_accuracy: 0.6181\n",
      "Epoch 14/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.6881 - val_loss: 0.7229 - val_accuracy: 0.6181\n",
      "Epoch 15/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.6998 - val_loss: 0.7202 - val_accuracy: 0.6260\n",
      "Epoch 16/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.7037 - val_loss: 0.7035 - val_accuracy: 0.6339\n",
      "Epoch 17/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6979 - val_loss: 0.6982 - val_accuracy: 0.6378\n",
      "Epoch 18/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.6998 - val_loss: 0.7126 - val_accuracy: 0.6063\n",
      "Epoch 19/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.6901 - val_loss: 0.6902 - val_accuracy: 0.6299\n",
      "Epoch 20/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7115 - val_loss: 0.6989 - val_accuracy: 0.6339\n",
      "Epoch 21/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.7212 - val_loss: 0.7014 - val_accuracy: 0.6063\n",
      "Epoch 22/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7135 - val_loss: 0.7009 - val_accuracy: 0.6024\n",
      "Epoch 23/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6998 - val_loss: 0.6660 - val_accuracy: 0.6260\n",
      "Epoch 24/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.7173 - val_loss: 0.6586 - val_accuracy: 0.6339\n",
      "Epoch 25/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.7135 - val_loss: 0.6515 - val_accuracy: 0.6339\n",
      "Epoch 26/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7310 - val_loss: 0.6549 - val_accuracy: 0.6260\n",
      "Epoch 27/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.7193 - val_loss: 0.6707 - val_accuracy: 0.6220\n",
      "Epoch 28/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7349 - val_loss: 0.6444 - val_accuracy: 0.6496\n",
      "Epoch 29/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7115 - val_loss: 0.6546 - val_accuracy: 0.6654\n",
      "Epoch 30/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7212 - val_loss: 0.6345 - val_accuracy: 0.6575\n",
      "Epoch 31/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7115 - val_loss: 0.6515 - val_accuracy: 0.6417\n",
      "Epoch 32/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.7251 - val_loss: 0.6302 - val_accuracy: 0.6614\n",
      "Epoch 33/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.7232 - val_loss: 0.6290 - val_accuracy: 0.6811\n",
      "Epoch 34/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.7290 - val_loss: 0.6250 - val_accuracy: 0.6693\n",
      "Epoch 35/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7388 - val_loss: 0.6396 - val_accuracy: 0.6417\n",
      "Epoch 36/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5625 - accuracy: 0.7310 - val_loss: 0.6225 - val_accuracy: 0.6654\n",
      "Epoch 37/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7310 - val_loss: 0.6232 - val_accuracy: 0.6732\n",
      "Epoch 38/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7349 - val_loss: 0.6483 - val_accuracy: 0.6339\n",
      "Epoch 39/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7329 - val_loss: 0.6204 - val_accuracy: 0.6772\n",
      "Epoch 40/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7368 - val_loss: 0.6157 - val_accuracy: 0.6811\n",
      "Epoch 41/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5638 - accuracy: 0.7310 - val_loss: 0.6205 - val_accuracy: 0.6693\n",
      "Epoch 42/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.7329 - val_loss: 0.6096 - val_accuracy: 0.6811\n",
      "Epoch 43/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7505 - val_loss: 0.6116 - val_accuracy: 0.6772\n",
      "Epoch 44/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5625 - accuracy: 0.7368 - val_loss: 0.6173 - val_accuracy: 0.6890\n",
      "Epoch 45/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7271 - val_loss: 0.6170 - val_accuracy: 0.6654\n",
      "Epoch 46/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.7349 - val_loss: 0.6103 - val_accuracy: 0.6772\n",
      "Epoch 47/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.7446 - val_loss: 0.6128 - val_accuracy: 0.6693\n",
      "Epoch 48/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7524 - val_loss: 0.6069 - val_accuracy: 0.6890\n",
      "Epoch 49/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7290 - val_loss: 0.6208 - val_accuracy: 0.6693\n",
      "Epoch 50/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7212 - val_loss: 0.6253 - val_accuracy: 0.6693\n",
      "Epoch 51/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7329 - val_loss: 0.6003 - val_accuracy: 0.6890\n",
      "Epoch 52/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.7446 - val_loss: 0.5996 - val_accuracy: 0.6929\n",
      "Epoch 53/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7485 - val_loss: 0.6020 - val_accuracy: 0.6811\n",
      "Epoch 54/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.7368 - val_loss: 0.5993 - val_accuracy: 0.7008\n",
      "Epoch 55/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.7485 - val_loss: 0.5989 - val_accuracy: 0.6732\n",
      "Epoch 56/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7388 - val_loss: 0.5958 - val_accuracy: 0.7008\n",
      "Epoch 57/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7427 - val_loss: 0.5966 - val_accuracy: 0.6811\n",
      "Epoch 58/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7388 - val_loss: 0.5950 - val_accuracy: 0.6850\n",
      "Epoch 59/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.7290 - val_loss: 0.6021 - val_accuracy: 0.6929\n",
      "Epoch 60/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7485 - val_loss: 0.5950 - val_accuracy: 0.6929\n",
      "Epoch 61/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7388 - val_loss: 0.6042 - val_accuracy: 0.6693\n",
      "Epoch 62/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7485 - val_loss: 0.5968 - val_accuracy: 0.6890\n",
      "Epoch 63/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.7251 - val_loss: 0.5999 - val_accuracy: 0.7008\n",
      "Epoch 64/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.7251 - val_loss: 0.6424 - val_accuracy: 0.6575\n",
      "Epoch 65/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7446 - val_loss: 0.5947 - val_accuracy: 0.6929\n",
      "Epoch 66/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7466 - val_loss: 0.5904 - val_accuracy: 0.6969\n",
      "Epoch 67/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7446 - val_loss: 0.6344 - val_accuracy: 0.6654\n",
      "Epoch 68/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.7368 - val_loss: 0.6300 - val_accuracy: 0.6535\n",
      "Epoch 69/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7446 - val_loss: 0.5894 - val_accuracy: 0.6929\n",
      "Epoch 70/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7505 - val_loss: 0.5958 - val_accuracy: 0.7008\n",
      "Epoch 71/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7329 - val_loss: 0.5924 - val_accuracy: 0.7047\n",
      "Epoch 72/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7466 - val_loss: 0.6088 - val_accuracy: 0.6890\n",
      "Epoch 73/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7349 - val_loss: 0.5918 - val_accuracy: 0.6811\n",
      "Epoch 74/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7485 - val_loss: 0.5872 - val_accuracy: 0.7008\n",
      "Epoch 75/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7368 - val_loss: 0.6054 - val_accuracy: 0.6850\n",
      "Epoch 76/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7446 - val_loss: 0.6113 - val_accuracy: 0.7087\n",
      "Epoch 77/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7407 - val_loss: 0.5894 - val_accuracy: 0.7047\n",
      "Epoch 78/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7407 - val_loss: 0.6035 - val_accuracy: 0.6929\n",
      "Epoch 79/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7349 - val_loss: 0.6021 - val_accuracy: 0.6969\n",
      "Epoch 80/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7466 - val_loss: 0.5986 - val_accuracy: 0.6850\n",
      "Epoch 81/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7388 - val_loss: 0.5961 - val_accuracy: 0.6850\n",
      "Epoch 82/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7329 - val_loss: 0.5987 - val_accuracy: 0.6929\n",
      "Epoch 83/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7407 - val_loss: 0.5948 - val_accuracy: 0.6929\n",
      "Epoch 84/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7407 - val_loss: 0.5873 - val_accuracy: 0.7008\n",
      "Epoch 85/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7466 - val_loss: 0.5904 - val_accuracy: 0.7047\n",
      "Epoch 86/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7466 - val_loss: 0.5975 - val_accuracy: 0.7087\n",
      "Epoch 87/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7466 - val_loss: 0.5940 - val_accuracy: 0.7047\n",
      "Epoch 88/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7524 - val_loss: 0.6015 - val_accuracy: 0.7008\n",
      "Epoch 89/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7505 - val_loss: 0.5862 - val_accuracy: 0.7008\n",
      "Epoch 90/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7544 - val_loss: 0.5815 - val_accuracy: 0.7165\n",
      "Epoch 91/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7349 - val_loss: 0.5936 - val_accuracy: 0.6929\n",
      "Epoch 92/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7485 - val_loss: 0.5833 - val_accuracy: 0.7008\n",
      "Epoch 93/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7271 - val_loss: 0.5795 - val_accuracy: 0.7087\n",
      "Epoch 94/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7310 - val_loss: 0.6381 - val_accuracy: 0.6969\n",
      "Epoch 95/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7388 - val_loss: 0.6042 - val_accuracy: 0.6929\n",
      "Epoch 96/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7407 - val_loss: 0.6043 - val_accuracy: 0.6850\n",
      "Epoch 97/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7427 - val_loss: 0.6004 - val_accuracy: 0.6969\n",
      "Epoch 98/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7505 - val_loss: 0.5901 - val_accuracy: 0.7008\n",
      "Epoch 99/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7407 - val_loss: 0.6042 - val_accuracy: 0.6890\n",
      "Epoch 100/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7310 - val_loss: 0.5904 - val_accuracy: 0.6890\n",
      "Epoch 101/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7466 - val_loss: 0.5950 - val_accuracy: 0.7008\n",
      "Epoch 102/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7466 - val_loss: 0.5983 - val_accuracy: 0.7165\n",
      "Epoch 103/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7524 - val_loss: 0.5935 - val_accuracy: 0.6890\n",
      "Epoch 104/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7583 - val_loss: 0.5823 - val_accuracy: 0.7087\n",
      "Epoch 105/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7544 - val_loss: 0.6491 - val_accuracy: 0.6654\n",
      "Epoch 106/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7368 - val_loss: 0.5767 - val_accuracy: 0.7205\n",
      "Epoch 107/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7407 - val_loss: 0.5724 - val_accuracy: 0.7047\n",
      "Epoch 108/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7602 - val_loss: 0.5774 - val_accuracy: 0.7008\n",
      "Epoch 109/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7544 - val_loss: 0.5774 - val_accuracy: 0.7008\n",
      "Epoch 110/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7505 - val_loss: 0.5857 - val_accuracy: 0.6969\n",
      "Epoch 111/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7407 - val_loss: 0.5723 - val_accuracy: 0.7205\n",
      "Epoch 112/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7485 - val_loss: 0.5701 - val_accuracy: 0.7087\n",
      "Epoch 113/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7583 - val_loss: 0.5862 - val_accuracy: 0.7165\n",
      "Epoch 114/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7427 - val_loss: 0.5904 - val_accuracy: 0.6890\n",
      "Epoch 115/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7563 - val_loss: 0.5952 - val_accuracy: 0.7008\n",
      "Epoch 116/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7388 - val_loss: 0.5710 - val_accuracy: 0.7283\n",
      "Epoch 117/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7310 - val_loss: 0.5749 - val_accuracy: 0.6969\n",
      "Epoch 118/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.7544 - val_loss: 0.5945 - val_accuracy: 0.6929\n",
      "Epoch 119/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7544 - val_loss: 0.5750 - val_accuracy: 0.7047\n",
      "Epoch 120/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7505 - val_loss: 0.5664 - val_accuracy: 0.7126\n",
      "Epoch 121/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7563 - val_loss: 0.5693 - val_accuracy: 0.7126\n",
      "Epoch 122/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7427 - val_loss: 0.5730 - val_accuracy: 0.7205\n",
      "Epoch 123/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7524 - val_loss: 0.5807 - val_accuracy: 0.6969\n",
      "Epoch 124/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7505 - val_loss: 0.5653 - val_accuracy: 0.7126\n",
      "Epoch 125/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7505 - val_loss: 0.5783 - val_accuracy: 0.7165\n",
      "Epoch 126/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7524 - val_loss: 0.5624 - val_accuracy: 0.7126\n",
      "Epoch 127/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7485 - val_loss: 0.5725 - val_accuracy: 0.7087\n",
      "Epoch 128/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7544 - val_loss: 0.5725 - val_accuracy: 0.7047\n",
      "Epoch 129/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7485 - val_loss: 0.5706 - val_accuracy: 0.7165\n",
      "Epoch 130/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7583 - val_loss: 0.5624 - val_accuracy: 0.6929\n",
      "Epoch 131/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7583 - val_loss: 0.5808 - val_accuracy: 0.7126\n",
      "Epoch 132/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7505 - val_loss: 0.6188 - val_accuracy: 0.7008\n",
      "Epoch 133/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7583 - val_loss: 0.5617 - val_accuracy: 0.7244\n",
      "Epoch 134/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7485 - val_loss: 0.5574 - val_accuracy: 0.7244\n",
      "Epoch 135/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7349 - val_loss: 0.5834 - val_accuracy: 0.7047\n",
      "Epoch 136/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7524 - val_loss: 0.5788 - val_accuracy: 0.7087\n",
      "Epoch 137/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7563 - val_loss: 0.5658 - val_accuracy: 0.7087\n",
      "Epoch 138/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7485 - val_loss: 0.5662 - val_accuracy: 0.7126\n",
      "Epoch 139/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7524 - val_loss: 0.5827 - val_accuracy: 0.7087\n",
      "Epoch 140/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7622 - val_loss: 0.5718 - val_accuracy: 0.7283\n",
      "Epoch 141/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7680 - val_loss: 0.5796 - val_accuracy: 0.7008\n",
      "Epoch 142/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7758 - val_loss: 0.5748 - val_accuracy: 0.7126\n",
      "Epoch 143/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7563 - val_loss: 0.5734 - val_accuracy: 0.7087\n",
      "Epoch 144/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7583 - val_loss: 0.5658 - val_accuracy: 0.7165\n",
      "Epoch 145/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7466 - val_loss: 0.5608 - val_accuracy: 0.7126\n",
      "Epoch 146/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7544 - val_loss: 0.5871 - val_accuracy: 0.7087\n",
      "Epoch 147/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7349 - val_loss: 0.5721 - val_accuracy: 0.7008\n",
      "Epoch 148/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7368 - val_loss: 0.5703 - val_accuracy: 0.7205\n",
      "Epoch 149/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7719 - val_loss: 0.5800 - val_accuracy: 0.7402\n",
      "Epoch 150/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7641 - val_loss: 0.5808 - val_accuracy: 0.7165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e8f190df70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85dbc130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5385227203369141, 0.7431551218032837]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06597996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
